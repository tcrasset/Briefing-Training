
# Project word embedding

NLP is a very interesting field that is undergoing a fascinating transition, as computing power rises,
the language models begin to come close to human-like tasks.
The big names in the game, which you will probably have heard of are BERT, GPT-3, and so on.
If you haven't, I encourage you to go and look at the things they can  do: [BERT](https://blog.google/products/search/search-language-understanding-bert/), [GPT-3](https://kitze.io/posts/gpt3-is-the-beginning-of-the-end)

If you follow the link to the video, you'll see how GPT-3 is used to create CSS code using only a single training example.

[![Watch the video](https://img.youtube.com/vi/TjUvMQvrjrg/0.jpg)](https://youtu.be/TjUvMQvrjrg)

Isn't that mindblowing ??

Although you are not Google or openAI with their hugely expensive models, you can build simpler models that can do nice things too.
The first step to this is creating word embeddings.
As you've seen in the course notes, creating word embeddings is the starting point for any NLP models.
You'll master this concept in no time and you'll be able to do things like the tweet you see above. Yay!

THe following assumes that you are familiar with how word embeddings work.
If not, you can always go back to [here](./project.md)
